{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okey\n"
     ]
    }
   ],
   "source": [
    "a = {'0': 10, '1': 20} \n",
    "\n",
    "if '0' in a.keys(): \n",
    "    print(\"okey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compile(self, b):\n",
    "        b.tasks = 1 \n",
    "        self.b = b \n",
    "        \n",
    "\n",
    "class B: \n",
    "    def __init(self): \n",
    "        self.tasks = 0 \n",
    "        pass \n",
    "\n",
    "\n",
    "a = A()\n",
    "a.compile(B()) \n",
    "getattr(getattr(a, 'b'), 'tasks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94583735, 2.40348754])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "mean= np.array([1,2]) \n",
    "cov = np.array([[1,0], [0,1]])\n",
    "\n",
    "np.random.multivariate_normal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]]\n",
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [1,2,3]]) \n",
    "print(a)\n",
    "print(np.mean(a, axis= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 4] \n",
    "b = a.copy() \n",
    "b[2] = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    'lr': [0,1, 2, 4], \n",
    "    'ma': [2,3,4],\n",
    "    'crossover':{\n",
    "        'gamma': [0.3, 0.4]\n",
    "    }\n",
    "}\n",
    "\n",
    "a = list(a.items()) \n",
    "print(a)\n",
    "print(type(a[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)): \n",
    "    a[i] = list(a[i])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a : \n",
    "    print(a.index((key, value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a : \n",
    "    print(key)\n",
    "a[0][1].insert(0, -2)\n",
    "a[0][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class a: \n",
    "    def __init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 4]\n",
    "a.insert(0, -1) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model.utils import * \n",
    "\n",
    "model  = loadModel(\"./RESULTS/tuning_smp/check.mso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(model.compile_kwargs['crossover'], 'gamma', 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(model.compile_kwargs['crossover'], 'gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.compile_kwargs.items(): \n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.kwargs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1, -2, -3, -1] \n",
    "a.remove(-1)\n",
    "a.remove(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.makedirs(\"./RESULTS/ahihi.01/\")\n",
    "path = os.path.join(\"./RESULTS/ahihi/a/\")\n",
    "os.makedirs(path+\"ma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(\"./RESULTS/SMP/gamma/0.4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"./RESULTS/ahihi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.removedirs(\"./RESULTS/ahihi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.kwargs.items(): \n",
    "    print(value)\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "a = pd.DataFrame([a], index=[\"com\"])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[0][0] = str(\"ad\") + a.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "a = [[1,2],[4,3]]\n",
    "name_row = [\"task1\", \"task2\"]\n",
    "name_col = [\"alg_1\", \"alg_2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a[:-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.index = name_row\n",
    "a.columns = name_col\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a, columns=name_col, index = name_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['task1']] = 'str' + df.loc[['task1']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['task1', :] = str(\"1\") + df['task1', :].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(name_row)-1): \n",
    "    argmin = np.argmin(a[row])\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(\"-oma\") + a[1].astype(str)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a, dtype= '<U3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ahihi(add):\n",
    "    pass \n",
    "    print(add) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahihi(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(a,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(10):\n",
    "    arr.append(np.arange(i, 1000, 50).tolist())\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileTM(path):\n",
    "    his_raw = pd.read_csv(path, header= None, usecols= np.arange(1, 301).tolist()).to_numpy()\n",
    "    arr = []\n",
    "    for i in range(10):\n",
    "        arr.append(np.arange(i, 300, 10).tolist())\n",
    "    arr = np.array(arr)\n",
    "    history_cost = np.zeros((1000, 10))\n",
    "    try:\n",
    "        for idx, idx_arr in enumerate(arr):\n",
    "            history_cost[:, idx] = np.average(his_raw[:, arr[idx]], axis = 1)\n",
    "    except:\n",
    "        print()\n",
    "    return history_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    # if idx_algo != 4: \n",
    "    #     continue\n",
    "    if idx_algo > 0: \n",
    "        break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        print(result.shape)\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    # if idx_algo != 4: \n",
    "    #     continue\n",
    "    if idx_algo > 0: \n",
    "        break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        print(result.shape)\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "a = np.array([[1,2],[3,4]]) \n",
    "np.average(a, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 1 or idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    if idx_algo != 1: \n",
    "        continue\n",
    "    # if idx_algo > 0: \n",
    "    #     break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        path_benchmark = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        path_remained_bechmark = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from MFEA_lib.model import AbstractModel\n",
    "from MFEA_lib.model.utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from MFEA_lib.tasks.Benchmark.Funcs import * \n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA_2021\n",
      "MTOSOO_P1.txt\n",
      "(100, 60)\n",
      "MTOSOO_P10.txt\n",
      "(100, 60)\n",
      "MTOSOO_P2.txt\n",
      "(100, 60)\n",
      "MTOSOO_P3.txt\n",
      "(100, 60)\n",
      "MTOSOO_P4.txt\n",
      "(100, 60)\n",
      "MTOSOO_P5.txt\n",
      "(100, 60)\n",
      "MTOSOO_P6.txt\n",
      "(100, 60)\n",
      "MTOSOO_P7.txt\n",
      "(100, 60)\n",
      "MTOSOO_P8.txt\n",
      "(100, 60)\n",
      "MTOSOO_P9.txt\n",
      "(100, 60)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "# name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "name = ['LSA_2021']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "# path = \"/home/tanminh/Downloads/MTO-Competition-CEC21/results/\"\n",
    "# path = \"D:/LinhTinh/MTO-Competition-CEC21/MTO-Competition-CEC21/results/results/\"\n",
    "path=\"/media/tanminh/New Volume/LinhTinh/Ubuntu/MTO-Competition-CEC21/results\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = ['MTO-Complex']\n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "\n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    # print(benchmark\n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(os.path.join(path, algorithm), benchmark) \n",
    "        # path_benchmark = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        result_link = path_benchmark\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        # print(result[0][1:].shape)\n",
    "        # print(result.shape)\n",
    "        print(benchmark)\n",
    "        result = result[:,1:] # shape = (1000,)\n",
    "        # 10 seed end\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(100, 2))\n",
    "        arr = [] \n",
    "        for idx_task in range(2): \n",
    "            arr.append(np.arange(idx_task, 2 * 30,2).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[:,arr[idx]], axis= 1)\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ls_history_cost[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_history_cost_task[\"LSA_2021_MTOMSO_P10.txt\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Saved'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = MultiTimeModel(AbstractModel, name= \"LSA_2021_MTOMSO_P5.txt\")\n",
    "model3.set_data(ls_history_cost_task[\"LSA_2021_MTOMSO_P5.txt\"])\n",
    "model3.tasks = None\n",
    "saveModel(model3, PATH = \"./RESULTS/MODEL3.mso\", remove_tasks= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = loadModel(\"./RESULTS/MODEL3.mso\", GECCO20_benchmark_50tasks.get_items(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA_2021_MTOSOO_P1.txt\n",
      "P1\n",
      "1\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_1.mso\n",
      "[608.00864307 607.89137403]\n",
      "LSA_2021_MTOSOO_P10.txt\n",
      "P10\n",
      "10\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_10.mso\n",
      "[2230.61177007 6263.21370613]\n",
      "LSA_2021_MTOSOO_P2.txt\n",
      "P2\n",
      "2\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_2.mso\n",
      "[700.0025424  700.00328443]\n",
      "LSA_2021_MTOSOO_P3.txt\n",
      "P3\n",
      "3\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_3.mso\n",
      "[5287.95026707 6475.5768689 ]\n",
      "LSA_2021_MTOSOO_P4.txt\n",
      "P4\n",
      "4\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_4.mso\n",
      "[1300.30108777 1300.2617392 ]\n",
      "LSA_2021_MTOSOO_P5.txt\n",
      "P5\n",
      "5\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_5.mso\n",
      "[1507.4175862  1508.07395407]\n",
      "LSA_2021_MTOSOO_P6.txt\n",
      "P6\n",
      "6\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_6.mso\n",
      "[6826.39746537 5556.1439513 ]\n",
      "LSA_2021_MTOSOO_P7.txt\n",
      "P7\n",
      "7\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_7.mso\n",
      "[2562.7353261  2605.39661367]\n",
      "LSA_2021_MTOSOO_P8.txt\n",
      "P8\n",
      "8\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_8.mso\n",
      "[520.02855527 520.0183064 ]\n",
      "LSA_2021_MTOSOO_P9.txt\n",
      "P9\n",
      "9\n",
      "Set complete!\n",
      "./RESULTS/result/LSA_2021_MTOMSO_Benchmark_9.mso\n",
      "[6853.14339687 1619.9632322 ]\n"
     ]
    }
   ],
   "source": [
    "for key, value in ls_history_cost_task.items(): \n",
    "    print(key)\n",
    "    model = MultiTimeModel(AbstractModel, name=key) \n",
    "    model.nb_run = 30\n",
    "    key = str(key).split(\".\")[0]\n",
    "    key = str(key).split(\"_\")[-1] # P3\n",
    "    id = int(str(key[1:]))\n",
    "    print(key)\n",
    "    print(id)\n",
    "    # model.tasks = CEC17_benchmark.get_2tasks_benchmark(ID = id)\n",
    "    model.tasks = None \n",
    "    model.set_data(value) \n",
    "    path = \"./RESULTS/result/LSA_2021_MTOMSO_Benchmark_\" + str(id) + \".mso\"\n",
    "    # path = \"./RESULTS/50tasks/d\" + str(id) + \".mso\"\n",
    "    print(path) \n",
    "    print(model.history_cost[-1])\n",
    "    # if id == 5: \n",
    "    #     model.render_history(yscale= 'log')\n",
    "    saveModel(model, PATH=path, remove_tasks= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"./RESULTS/50tasks/dm5.mso\", GECCO20_benchmark_50tasks.get_items(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for id in range(9, 11):\n",
    "    print(id)\n",
    "    model = loadModel(\"./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_{}.mso\".format(str(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history_cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')\n",
    "model2 = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')\n",
    "compare = CompareModel([model, model2]) \n",
    "compare.compareResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.render_history(yscale= 'log')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_history_cost_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_history_cost[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ls_history_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test IDPC-EDU </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "with open(\"/MFEA_lib/tasks/__references__/IDPC_DU/IDPC_EDU/data/set1/idpc_10x5x425.idpc\") as f: \n",
    "    data = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.tasks.task import * \n",
    "\n",
    "idpc = IDPC_EDU(path=\"/__references__/IDPC_DU/IDPC_EDU/data/set1/idpc_10x5x425.idpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Population</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.EA import * \n",
    "from MFEA_lib.tasks.Benchmark import CEC17_benchmark\n",
    "cec = CEC17_benchmark.get_10tasks_benchmark()\n",
    "a = SubPopulation(1, 10, 50, bound=[0,1], task=cec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(): \n",
    "    def __init__(self): \n",
    "        self.b  = 10 \n",
    "        self.c = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A() : \n",
    "    def __init__(self): \n",
    "        self.ls_inds = [B() for i in range(10)]\n",
    "    def __getitem__(self, index): \n",
    "        return self.ls_inds[index] \n",
    "    \n",
    "    \n",
    "\n",
    "a = A() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.EA import * \n",
    "from MFEA_lib.tasks import Benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cec17 = Benchmark.CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.9] * 25 + [0.1] * 25) \n",
    "print(cec17[9].func(a))\n",
    "b = np.array( [0.89999999992] * 1 + [0.9] * 24 + [0.1] * 24 + [0.10000000009] * 1)\n",
    "print(cec17[9].func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.8999999999999999] * 50) \n",
    "print(cec17[1].func(a))\n",
    "b = np.array([0.8999999999999884]*49 + [0.90000000001])\n",
    "print(cec17[1].func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = EA.SubPopulation(skill_factor= 1, num_inds= 20, dim = 50, task= cec17[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update_rank() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = np.random.choice(np.where(a.scalar_fitness >= 1/(0.1 * len(a)))[0])\n",
    "print(np.where(a.scalar_fitness >= 1/(0.1 * len(a)))[0])\n",
    "print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a) == SubPopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [a[i].genes[0] for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.random.choice([3,4], size= 2 , replace= True)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inds_tasks = np.zeros(shape = (len(cec17)), dtype= int) + 10\n",
    "dim = 50\n",
    "\n",
    "pop = Population(nb_inds_tasks = num_inds_tasks, dim = dim, list_tasks= cec17)\n",
    "itemgetter(*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Individual </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pop[0].__getRandomItems__(size= 1)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 2, 4, 3]) \n",
    "A[np.array([1, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pop[0].ls_inds[np.random.choice(np.arange(len(pop[0])), size= (3,))]\n",
    "# NOTE \n",
    "\n",
    "b = np.random.choice(len(pop[0]), size= (3,))\n",
    "array = np.zeros(shape= (3,), dtype= int) + 1 \n",
    "pop[0].ls_inds[array.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pop.__getRandomInds__(size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind3.fcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind3.skill_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(pop[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "\n",
    "def someMethod(self, arg1, kwarg1=None):\n",
    "    pass\n",
    "\n",
    "sig = signature(someMethod)\n",
    "print(type(sig))\n",
    "print(sig.parameters)\n",
    "print(list(sig.parameters.keys())[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8da01e5a71448ea74f54d88afa8911010d1d12e23bc7e103d40d5def4a09152c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
