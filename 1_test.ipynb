{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okey\n"
     ]
    }
   ],
   "source": [
    "a = {'0': 10, '1': 20} \n",
    "\n",
    "if '0' in a.keys(): \n",
    "    print(\"okey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compile(self, b):\n",
    "        b.tasks = 1 \n",
    "        self.b = b \n",
    "        \n",
    "\n",
    "class B: \n",
    "    def __init(self): \n",
    "        self.tasks = 0 \n",
    "        pass \n",
    "\n",
    "\n",
    "a = A()\n",
    "a.compile(B()) \n",
    "getattr(getattr(a, 'b'), 'tasks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 4] \n",
    "b = a.copy() \n",
    "b[2] = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    'lr': [0,1, 2, 4], \n",
    "    'ma': [2,3,4],\n",
    "    'crossover':{\n",
    "        'gamma': [0.3, 0.4]\n",
    "    }\n",
    "}\n",
    "\n",
    "a = list(a.items()) \n",
    "print(a)\n",
    "print(type(a[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)): \n",
    "    a[i] = list(a[i])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a : \n",
    "    print(a.index((key, value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a : \n",
    "    print(key)\n",
    "a[0][1].insert(0, -2)\n",
    "a[0][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class a: \n",
    "    def __init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 4]\n",
    "a.insert(0, -1) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model.utils import * \n",
    "\n",
    "model  = loadModel(\"./RESULTS/tuning_smp/check.mso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(model.compile_kwargs['crossover'], 'gamma', 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(model.compile_kwargs['crossover'], 'gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.compile_kwargs.items(): \n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.kwargs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [-1, -2, -3, -1] \n",
    "a.remove(-1)\n",
    "a.remove(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.makedirs(\"./RESULTS/ahihi.01/\")\n",
    "path = os.path.join(\"./RESULTS/ahihi/a/\")\n",
    "os.makedirs(path+\"ma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(\"./RESULTS/SMP/gamma/0.4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"./RESULTS/ahihi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.removedirs(\"./RESULTS/ahihi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.kwargs.items(): \n",
    "    print(value)\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "a = pd.DataFrame([a], index=[\"com\"])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[0][0] = str(\"ad\") + a.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "a = [[1,2],[4,3]]\n",
    "name_row = [\"task1\", \"task2\"]\n",
    "name_col = [\"alg_1\", \"alg_2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a[:-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.index = name_row\n",
    "a.columns = name_col\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a, columns=name_col, index = name_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['task1']] = 'str' + df.loc[['task1']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['task1', :] = str(\"1\") + df['task1', :].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(name_row)-1): \n",
    "    argmin = np.argmin(a[row])\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(\"-oma\") + a[1].astype(str)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a, dtype= '<U3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ahihi(add):\n",
    "    pass \n",
    "    print(add) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahihi(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(a,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(10):\n",
    "    arr.append(np.arange(i, 1000, 50).tolist())\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileTM(path):\n",
    "    his_raw = pd.read_csv(path, header= None, usecols= np.arange(1, 301).tolist()).to_numpy()\n",
    "    arr = []\n",
    "    for i in range(10):\n",
    "        arr.append(np.arange(i, 300, 10).tolist())\n",
    "    arr = np.array(arr)\n",
    "    history_cost = np.zeros((1000, 10))\n",
    "    try:\n",
    "        for idx, idx_arr in enumerate(arr):\n",
    "            history_cost[:, idx] = np.average(his_raw[:, arr[idx]], axis = 1)\n",
    "    except:\n",
    "        print()\n",
    "    return history_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    # if idx_algo != 4: \n",
    "    #     continue\n",
    "    if idx_algo > 0: \n",
    "        break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        print(result.shape)\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    # if idx_algo != 4: \n",
    "    #     continue\n",
    "    if idx_algo > 0: \n",
    "        break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        print(result.shape)\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "a = np.array([[1,2],[3,4]]) \n",
    "np.average(a, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "path = \"D:/LinhTinh/result_run_cec_gecco/seed_0_to_20\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = os.listdir(path) \n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "    # if idx_algo == 1 or idx_algo == 4 or idx_algo == 2:\n",
    "    #     continue\n",
    "    if idx_algo != 1: \n",
    "        continue\n",
    "    # if idx_algo > 0: \n",
    "    #     break \n",
    "    # take the benchmark \n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    assert len(benchmarks) == 10 \n",
    "    path_algo = os.path.join(path, algorithm) \n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(path_algo, benchmark) \n",
    "        path_benchmark = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        result_link = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        # print(result[0][1:].shape)\n",
    "        result = result[0][1:] # shape = (1000,)\n",
    "        # 10 seed end \n",
    "        path_remained_bechmark = os.path.join(os.path.join(remain_path, algorithm), benchmark)\n",
    "        path_remained_bechmark = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        result_link_2 = os.path.join(path_remained_bechmark, os.listdir(path_remained_bechmark)[0])\n",
    "        # print(result_link_2)\n",
    "        result_2 = pd.read_csv(result_link_2, header=None).to_numpy()\n",
    "        result_2 = result_2[0][1001:]\n",
    "        # print(result_2.shape)\n",
    "        # calculat \n",
    "        # concate\n",
    "        result = np.concatenate([result, result_2], axis= 0)\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500, 50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[arr[idx]])\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from MFEA_lib.model import AbstractModel\n",
    "from MFEA_lib.model.utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from MFEA_lib.tasks.Benchmark import CEC17_benchmark, GECCO20_benchmark_50tasks\n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "from MFEA_lib.tasks.Benchmark import CEC17_benchmark, GECCO20_benchmark_50tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA_2021\n",
      "MTOMSO_P1.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P10.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P2.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P3.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P4.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P5.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P6.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P7.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P8.txt\n",
      "(1000, 1500)\n",
      "MTOMSO_P9.txt\n",
      "(1000, 1500)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "# name = [\"EBS_GA\", \"SA\", \"LSA\",\"MFEA\", \"MaTDE\", \"MaTGA\", 'SBS_GA_poly', 'SBS_GA']\n",
    "name = ['LSA_2021']\n",
    "ls_history_cost = []\n",
    "ls_history_cost_task = {}\n",
    "# path = \"/home/tanminh/Downloads/MTO-Competition-CEC21/results/\"\n",
    "path = \"D:/LinhTinh/MTO-Competition-CEC21/MTO-Competition-CEC21/results/results/\"\n",
    "remain_path = \"D:/LinhTinh/result_run_cec_gecco/seed_20_to_30\"\n",
    "list_algo = ['MTO-Many']\n",
    "\n",
    "for idx_algo  in range(len(list_algo)): \n",
    "    print(name[idx_algo])\n",
    "    algorithm = list_algo[idx_algo] \n",
    "\n",
    "    benchmarks = os.listdir(os.path.join(path, algorithm))\n",
    "    # print(benchmark\n",
    "    for benchmark in benchmarks: \n",
    "        # 20 seed first\n",
    "        path_benchmark = os.path.join(os.path.join(path, algorithm), benchmark) \n",
    "        # path_benchmark = os.path.join(path_benchmark, os.listdir(path_benchmark)[0])\n",
    "        result_link = path_benchmark\n",
    "        # print(result_link)\n",
    "        result = pd.read_csv(result_link, header=None).to_numpy()\n",
    "        # print(result[0][1:].shape)\n",
    "        # print(result.shape)\n",
    "        print(benchmark)\n",
    "        result = result[:,1:] # shape = (1000,)\n",
    "        # 10 seed end\n",
    "        print(result.shape)\n",
    "        # result.reshape((1000,1))\n",
    "        \n",
    "        history_cost = np.zeros(shape=(1000, 50))\n",
    "        arr = [] \n",
    "        for idx_task in range(50): \n",
    "            arr.append(np.arange(idx_task, 1500,50).tolist())\n",
    "        arr = np.array(arr)\n",
    "        \n",
    "        for idx, task in enumerate(arr): \n",
    "            history_cost[:, idx] = np.average(result[:,arr[idx]], axis= 1)\n",
    "        \n",
    "        ls_history_cost.append(history_cost.tolist())\n",
    "        ls_history_cost_task[str(name[idx_algo]) + \"_\"+ benchmark] = history_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ls_history_cost[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_history_cost_task[\"LSA_2021_MTOMSO_P10.txt\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Saved'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = MultiTimeModel(AbstractModel, name= \"LSA_2021_MTOMSO_P5.txt\")\n",
    "model3.set_data(ls_history_cost_task[\"LSA_2021_MTOMSO_P5.txt\"])\n",
    "model3.tasks = None\n",
    "saveModel(model3, PATH = \"./RESULTS/MODEL3.mso\", remove_tasks= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = loadModel(\"./RESULTS/MODEL3.mso\", GECCO20_benchmark_50tasks.get_items(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA_2021_MTOMSO_P1.txt\n",
      "P1\n",
      "1\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_1.mso\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "LSA_2021_MTOMSO_P10.txt\n",
      "P10\n",
      "10\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_10.mso\n",
      "[1.58735757e+00 6.23838585e+01 5.74100000e-03 8.47304277e+00\n",
      " 4.09549991e+03 1.29842247e+00 6.81214422e+01 5.00280000e-03\n",
      " 8.46530457e+00 4.50674604e+03 1.55128177e+00 6.29145064e+01\n",
      " 4.35153333e-03 9.15054567e+00 3.74006666e+03 3.17274850e+00\n",
      " 5.82050427e+01 4.10626667e-03 8.34515617e+00 3.95072047e+03\n",
      " 1.33381147e+00 6.45064301e+01 4.51160000e-03 8.14397123e+00\n",
      " 3.81187195e+03 1.60851397e+00 6.36441401e+01 3.85993333e-03\n",
      " 8.63148257e+00 3.82358288e+03 1.45795030e+00 6.53899428e+01\n",
      " 2.62866667e-03 9.31050890e+00 4.05068870e+03 1.58411133e+00\n",
      " 6.33375200e+01 4.84400000e-03 7.51238040e+00 4.32191625e+03\n",
      " 1.83258187e+00 6.51697488e+01 4.51506667e-03 9.37716100e+00\n",
      " 4.34121904e+03 2.39144157e+00 6.60320358e+01 5.58320000e-03\n",
      " 9.98441067e+00 3.86589128e+03]\n",
      "LSA_2021_MTOMSO_P2.txt\n",
      "P2\n",
      "2\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_2.mso\n",
      "[41.531714   51.04230153 32.92012187 35.20167993 52.0097806  53.07877597\n",
      " 46.55911573 39.55177973 59.1941069  46.8482936  42.4970499  39.14610063\n",
      " 45.17571243 57.1694924  47.21891943 41.64929933 34.42108673 60.92489523\n",
      " 39.37357127 34.86386137 34.55337193 46.73504403 31.1118149  41.0723581\n",
      " 31.80273053 44.0568369  42.98660457 46.46416497 35.99967573 49.07652077\n",
      " 51.2326207  40.2353592  52.37830077 39.41962927 49.62291033 40.7230156\n",
      " 48.48411443 38.85905653 51.41417657 49.9477681  63.44952077 29.00325193\n",
      " 52.7673357  25.23069607 49.906104   50.79582587 30.77937573 30.65775847\n",
      " 64.95314257 34.14291913]\n",
      "LSA_2021_MTOMSO_P3.txt\n",
      "P3\n",
      "3\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_3.mso\n",
      "[54.8885224  60.26129203 57.17691737 58.00605623 57.7738984  60.69243907\n",
      " 57.04432997 59.36582837 56.38095747 51.33984317 59.8301392  59.66431843\n",
      " 56.1819739  57.80706013 53.36292237 55.02118237 56.9779312  59.0673421\n",
      " 57.54173777 62.2511913  55.85030843 57.57490447 57.80706087 54.88852117\n",
      " 57.90674747 52.8323204  54.72269847 59.4984843  59.23322563 62.68234683\n",
      " 58.10170447 58.6030283  60.68209803 55.7176527  57.593081   58.86834907\n",
      " 59.76380797 55.34578517 53.62824153 57.5417327  56.613116   55.1206757\n",
      " 58.43672747 58.6681685  59.29512847 63.1426603  54.78902427 60.52660977\n",
      " 58.24278417 59.33266497]\n",
      "LSA_2021_MTOMSO_P4.txt\n",
      "P4\n",
      "4\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_4.mso\n",
      "[ 0.         10.47177277  0.38632443  0.         13.61661263  0.1985979\n",
      "  0.          6.77020893  0.11079707  0.          6.28300127  0.44162927\n",
      "  0.         14.69153743  0.42768387  0.         13.40298757  0.25280657\n",
      "  0.          6.43600353  0.42734307  0.          9.6376111   0.23148933\n",
      "  0.         10.85580943  0.57702077  0.         31.809337    0.45710857\n",
      "  0.          9.520122    0.3142827   0.         23.18981063  0.3376616\n",
      "  0.          6.0306856   0.2610626   0.         11.80502563  0.19399803\n",
      "  0.          5.97576357  0.5676041   0.          5.95417923  0.42399913\n",
      "  0.         26.13625267]\n",
      "LSA_2021_MTOMSO_P5.txt\n",
      "P5\n",
      "5\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_5.mso\n",
      "[5.73759140e+01 3.85950000e-03 3.86783033e+00 5.96311795e+01\n",
      " 3.20446667e-03 4.27608640e+00 6.07587675e+01 2.46510000e-03\n",
      " 3.44239437e+00 5.97959716e+01 4.02450000e-03 3.60256533e+00\n",
      " 6.59988681e+01 3.93896667e-03 3.66390337e+00 6.39757954e+01\n",
      " 4.59896667e-03 4.05991397e+00 6.13557405e+01 3.77023333e-03\n",
      " 3.64359417e+00 6.34783181e+01 3.12100000e-03 4.80851253e+00\n",
      " 6.12230789e+01 6.80970000e-03 4.80824617e+00 6.00291299e+01\n",
      " 4.76213333e-03 4.33786800e+00 6.29808322e+01 5.74550000e-03\n",
      " 4.15488263e+00 5.85479498e+01 4.02223333e-03 3.59318013e+00\n",
      " 5.99659539e+01 5.58133333e-03 4.29389730e+00 6.28594518e+01\n",
      " 2.46363333e-03 3.70363090e+00 6.18532240e+01 4.51120000e-03\n",
      " 3.94390673e+00 5.96950794e+01 5.99310000e-03 3.93516427e+00\n",
      " 6.65295106e+01 2.05380000e-03]\n",
      "LSA_2021_MTOMSO_P6.txt\n",
      "P6\n",
      "6\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_6.mso\n",
      "[3.37401223e+01 2.46393333e-03 5.95515956e+03 2.00960590e+01\n",
      " 2.21846667e-03 5.88274615e+03 3.96470042e+01 2.54580000e-03\n",
      " 5.88115477e+03 2.70191788e+01 4.76016667e-03 5.89004179e+03\n",
      " 4.37443098e+01 2.71060000e-03 5.61527590e+03 2.99051097e+01\n",
      " 3.20060000e-03 5.61778988e+03 1.83626317e+01 3.53110000e-03\n",
      " 5.59286288e+03 3.41718931e+01 1.23226667e-03 5.60951296e+03\n",
      " 2.98941885e+01 1.31496667e-03 5.72055519e+03 2.01636502e+01\n",
      " 3.77676667e-03 5.51819932e+03 4.30395094e+01 2.05086667e-03\n",
      " 5.49819060e+03 2.78114133e+01 1.56073333e-03 5.82183430e+03\n",
      " 2.83735556e+01 2.38116667e-03 5.91757248e+03 4.72554284e+01\n",
      " 3.20150000e-03 5.92044788e+03 3.11147544e+01 4.10506667e-03\n",
      " 5.59634244e+03 3.85792037e+01 2.71030000e-03 5.75405161e+03\n",
      " 4.02848808e+01 2.05240000e-03]\n",
      "LSA_2021_MTOMSO_P7.txt\n",
      "P7\n",
      "7\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_7.mso\n",
      "[ 0.27041093 60.36078593  4.0177752   0.29715517 65.43505927  4.33012437\n",
      "  0.4403708  60.72560343  4.44880733  0.47508643 59.5648147   4.66707593\n",
      "  0.4185845  63.04715887  4.73342163  0.52585657 67.5576331   4.17091933\n",
      "  0.43380613 62.71562577  4.28282663  0.50835103 63.01400313  4.18390047\n",
      "  0.54102857 60.32762477  4.6176113   0.49013727 63.40782643  4.40119707\n",
      "  0.3690303  65.16974023  3.82639033  0.45111967 60.2612883   4.34114283\n",
      "  0.47030683 63.33653843  4.12190733  0.2618047  63.27937723  4.29020133\n",
      "  0.63313563 67.3085113   4.43330563  0.40870257 64.8857701   4.24455733\n",
      "  0.47660997 63.4247478 ]\n",
      "LSA_2021_MTOMSO_P8.txt\n",
      "P8\n",
      "8\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_8.mso\n",
      "[2.95263169e+01 1.65067080e+00 6.67616617e+01 2.38043333e-03\n",
      " 7.87393370e+00 4.69583966e+01 1.24239113e+00 6.66621730e+01\n",
      " 1.72433333e-03 9.02732613e+00 3.31429569e+01 1.50396390e+00\n",
      " 6.72923187e+01 3.28460000e-03 9.88835140e+00 3.92649607e+01\n",
      " 1.29848633e+00 6.48712526e+01 2.38033333e-03 8.60663800e+00\n",
      " 2.62964031e+01 1.45040767e+00 6.06925332e+01 3.20223333e-03\n",
      " 8.20407617e+00 2.58632628e+01 1.34772273e+00 6.35446380e+01\n",
      " 1.56016667e-03 7.62639200e+00 5.88976181e+01 1.46837167e+00\n",
      " 6.50425965e+01 1.23200000e-03 7.64318527e+00 2.81747276e+01\n",
      " 1.54227447e+00 6.21848742e+01 9.85633333e-04 8.67168220e+00\n",
      " 4.78665454e+01 1.36982370e+00 6.63305167e+01 5.74540000e-03\n",
      " 7.49843930e+00 2.98562847e+01 1.35299437e+00 6.98355952e+01\n",
      " 1.88916667e-03 7.20618423e+00]\n",
      "LSA_2021_MTOMSO_P9.txt\n",
      "P9\n",
      "9\n",
      "Set complete!\n",
      "./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_9.mso\n",
      "[4.42746177e+01 1.39418613e+00 6.83535966e+01 3.85840000e-03\n",
      " 8.76389833e+00 4.23587423e+03 1.91705381e+01 1.38366970e+00\n",
      " 6.54018894e+01 4.51480000e-03 8.78623320e+00 3.90033828e+03\n",
      " 2.69100710e+01 1.32476503e+00 6.41095531e+01 4.67916667e-03\n",
      " 7.70307900e+00 3.97203728e+03 1.95701799e+01 1.35160370e+00\n",
      " 6.73254761e+01 5.00823333e-03 9.86645760e+00 3.94954178e+03\n",
      " 6.16153960e+01 1.72374530e+00 6.59325407e+01 4.51633333e-03\n",
      " 8.55136517e+00 4.57795924e+03 4.11966745e+01 1.48272600e+00\n",
      " 6.61072923e+01 1.80733333e-03 9.13752690e+00 4.30435155e+03\n",
      " 5.19087189e+01 1.50760217e+00 6.38762975e+01 5.41916667e-03\n",
      " 7.96546403e+00 3.52264798e+03 2.71547351e+01 1.37185083e+00\n",
      " 6.38762972e+01 5.09170000e-03 8.52303920e+00 3.97306138e+03\n",
      " 2.64341778e+01 1.70404597e+00]\n"
     ]
    }
   ],
   "source": [
    "for key, value in ls_history_cost_task.items(): \n",
    "    print(key)\n",
    "    model = MultiTimeModel(AbstractModel, name=key) \n",
    "    model.nb_run = 30\n",
    "    key = str(key).split(\".\")[0]\n",
    "    key = str(key).split(\"_\")[-1] # P3\n",
    "    id = int(str(key[1:]))\n",
    "    print(key)\n",
    "    print(id)\n",
    "    # model.tasks = CEC17_benchmark.get_2tasks_benchmark(ID = id)\n",
    "    model.tasks = None \n",
    "    model.set_data(value) \n",
    "    path = \"./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_\" + str(id) + \".mso\"\n",
    "    # path = \"./RESULTS/50tasks/d\" + str(id) + \".mso\"\n",
    "    print(path) \n",
    "    print(model.history_cost[-1])\n",
    "    # if id == 5: \n",
    "    #     model.render_history(yscale= 'log')\n",
    "    saveModel(model, PATH=path, remove_tasks= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel(\"./RESULTS/50tasks/dm5.mso\", GECCO20_benchmark_50tasks.get_items(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for id in range(9, 11):\n",
    "    print(id)\n",
    "    model = loadModel(\"./RESULTS/50tasks/LSA_2021_MTOMSO_Benchmark_{}.mso\".format(str(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history_cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')\n",
    "model2 = loadModel('./RESULTS/50tasks/SBS_GA_poly_Benchmark_3.mso')\n",
    "compare = CompareModel([model, model2]) \n",
    "compare.compareResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.render_history(yscale= 'log')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_history_cost_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_history_cost[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ls_history_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test IDPC-EDU </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "with open(\"/MFEA_lib/tasks/__references__/IDPC_DU/IDPC_EDU/data/set1/idpc_10x5x425.idpc\") as f: \n",
    "    data = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.tasks.task import * \n",
    "\n",
    "idpc = IDPC_EDU(path=\"/__references__/IDPC_DU/IDPC_EDU/data/set1/idpc_10x5x425.idpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Population</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.EA import * \n",
    "from MFEA_lib.tasks.Benchmark import CEC17_benchmark\n",
    "cec = CEC17_benchmark.get_10tasks_benchmark()\n",
    "a = SubPopulation(1, 10, 50, bound=[0,1], task=cec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(): \n",
    "    def __init__(self): \n",
    "        self.b  = 10 \n",
    "        self.c = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A() : \n",
    "    def __init__(self): \n",
    "        self.ls_inds = [B() for i in range(10)]\n",
    "    def __getitem__(self, index): \n",
    "        return self.ls_inds[index] \n",
    "    \n",
    "    \n",
    "\n",
    "a = A() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.EA import * \n",
    "from MFEA_lib.tasks import Benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cec17 = Benchmark.CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.9] * 25 + [0.1] * 25) \n",
    "print(cec17[9].func(a))\n",
    "b = np.array( [0.89999999992] * 1 + [0.9] * 24 + [0.1] * 24 + [0.10000000009] * 1)\n",
    "print(cec17[9].func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.8999999999999999] * 50) \n",
    "print(cec17[1].func(a))\n",
    "b = np.array([0.8999999999999884]*49 + [0.90000000001])\n",
    "print(cec17[1].func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = EA.SubPopulation(skill_factor= 1, num_inds= 20, dim = 50, task= cec17[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update_rank() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = np.random.choice(np.where(a.scalar_fitness >= 1/(0.1 * len(a)))[0])\n",
    "print(np.where(a.scalar_fitness >= 1/(0.1 * len(a)))[0])\n",
    "print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a) == SubPopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [a[i].genes[0] for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.random.choice([3,4], size= 2 , replace= True)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inds_tasks = np.zeros(shape = (len(cec17)), dtype= int) + 10\n",
    "dim = 50\n",
    "\n",
    "pop = Population(nb_inds_tasks = num_inds_tasks, dim = dim, list_tasks= cec17)\n",
    "itemgetter(*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Individual </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pop[0].__getRandomItems__(size= 1)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 2, 4, 3]) \n",
    "A[np.array([1, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pop[0].ls_inds[np.random.choice(np.arange(len(pop[0])), size= (3,))]\n",
    "# NOTE \n",
    "\n",
    "b = np.random.choice(len(pop[0]), size= (3,))\n",
    "array = np.zeros(shape= (3,), dtype= int) + 1 \n",
    "pop[0].ls_inds[array.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pop.__getRandomInds__(size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind3.fcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind3.skill_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(pop[i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "\n",
    "def someMethod(self, arg1, kwarg1=None):\n",
    "    pass\n",
    "\n",
    "sig = signature(someMethod)\n",
    "print(type(sig))\n",
    "print(sig.parameters)\n",
    "print(list(sig.parameters.keys())[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8da01e5a71448ea74f54d88afa8911010d1d12e23bc7e103d40d5def4a09152c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
